{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and DAta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os\n",
    "import matplotlib.pyplot as plt#visualization\n",
    "from PIL import  Image\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns#visualization\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import io\n",
    "import plotly.offline as py#visualization\n",
    "py.init_notebook_mode(connected=True)#visualization\n",
    "import plotly.graph_objs as go#visualization\n",
    "import plotly.tools as tls#visualization\n",
    "import plotly.figure_factory as ff#visualization\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,scorer\n",
    "from sklearn.metrics import f1_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from yellowbrick.classifier import DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_om_demo_data_1-25-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3742102, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = df.drop(columns= ['Unnamed: 0','orderDate','eventTime','order_no','CURR_LINE_STATUS','inhand_date','eventTime','CARRIER','TRACKING_NUMBER'])\n",
    "dfm = dfm.drop(columns = ['EXTN_CARR_NM','SHIP_NODE','loc_id','loc_cut_off_time','loc_air_cut_off_time','ORIG_CUST_PROMISE_DT','CURR_CUST_PROMISE_DT'])\n",
    "dfm = dfm.drop(columns = ['UPS_SVC_CDE'])\n",
    "dfm = dfm.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change purchase month to string type\n",
    "#dfm['actual_ship_method_ups'] = dfm['actual_ship_method_ups'].astype(str)\n",
    "\n",
    "#seperate air and ground\n",
    "air = dfm[dfm.actual_ship_method_ups == 'air']\n",
    "ground = dfm[dfm.actual_ship_method_ups == 'ground']\n",
    "\n",
    "#seperate catagorical and numberical columns\n",
    "id_col = ['order_line_key']\n",
    "target_col = ['actual_ship_method_ups']\n",
    "\n",
    "#if column has less than 13 unique values consider it categorical\n",
    "cat_cols = dfm.nunique()[dfm.nunique() < 20].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "num_cols   = [x for x in dfm.columns if x not in cat_cols + target_col + id_col]\n",
    "\n",
    "#Binary columns with 2 values\n",
    "bin_cols   = dfm.nunique()[dfm.nunique() == 2].keys().tolist()\n",
    "#Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "#Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    dfm[i] = le.fit_transform(dfm[i])\n",
    "    \n",
    "#Duplicating columns for multi value columns\n",
    "dfm = pd.get_dummies(data = dfm,columns = multi_cols )\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(dfm[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_df_og = dfm.copy()\n",
    "dfm = dfm.drop(columns = num_cols,axis = 1)\n",
    "dfm = dfm.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "\n",
    "#df = df.dropna()\n",
    "#splitting train and test data \n",
    "train,test = train_test_split(dfm,test_size = .25 ,random_state = 111)\n",
    "\n",
    "cols    = [i for i in dfm.columns if i not in id_col + target_col]\n",
    "train_X = train[cols]\n",
    "train_Y = train[target_col]\n",
    "test_X  = test[cols]\n",
    "test_Y  = test[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Logit Modeling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function attributes\n",
    "#dataframe     - processed dataframe\n",
    "#Algorithm     - Algorithm used \n",
    "#training_x    - predictor variables dataframe(training)\n",
    "#testing_x     - predictor variables dataframe(testing)\n",
    "#training_y    - target variable(training)\n",
    "#training_y    - target variable(testing)\n",
    "#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n",
    "                                 #regression,features for tree based models)\n",
    "\n",
    "#threshold_plot - if True returns threshold plot for model\n",
    "    \n",
    "def churn_prediction(algorithm,training_x,testing_x,\n",
    "                             training_y,testing_y,cols,cf,threshold_plot) :\n",
    "    \n",
    "    #model\n",
    "    algorithm.fit(training_x,training_y)\n",
    "    predictions   = algorithm.predict(testing_x)\n",
    "    probabilities = algorithm.predict_proba(testing_x)\n",
    "    #coeffs\n",
    "    if   cf == \"coefficients\" :\n",
    "        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n",
    "    elif cf == \"features\" :\n",
    "        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n",
    "        \n",
    "    column_df     = pd.DataFrame(cols)\n",
    "    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_sumry.columns = [\"coefficients\",\"features\"]\n",
    "    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    print (algorithm)\n",
    "    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n",
    "    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n",
    "    #confusion matrix\n",
    "    conf_matrix = confusion_matrix(testing_y,predictions)\n",
    "    #roc_auc_score\n",
    "    model_roc_auc = roc_auc_score(testing_y,predictions) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n",
    "    \n",
    "    #plot confusion matrix\n",
    "    trace1 = go.Heatmap(z = conf_matrix ,\n",
    "                        x = [\"predicted air\",\"predicted ground\"],\n",
    "                        y = [\"actual air\",\"acutal ground\"],\n",
    "                        showscale  = False,colorscale = \"Picnic\",\n",
    "                        name = \"matrix\")\n",
    "    \n",
    "    #plot roc curve\n",
    "    trace2 = go.Scatter(x = fpr,y = tpr,\n",
    "                        name = \"Roc : \" + str(model_roc_auc),\n",
    "                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n",
    "    trace3 = go.Scatter(x = [0,1],y=[0,1],\n",
    "                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    #plot coeffs\n",
    "    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_sumry[\"coefficients\"],\n",
    "                                  colorscale = \"Picnic\",\n",
    "                                  line = dict(width = .6,color = \"black\")))\n",
    "    \n",
    "    #subplots\n",
    "    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                            subplot_titles=('Confusion Matrix',\n",
    "                                            'Receiver operating characteristic',\n",
    "                                            'Feature Importances'))\n",
    "    \n",
    "    fig.append_trace(trace1,1,1)\n",
    "    fig.append_trace(trace2,1,2)\n",
    "    fig.append_trace(trace3,1,2)\n",
    "    fig.append_trace(trace4,2,1)\n",
    "    \n",
    "    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n",
    "                         autosize = False,height = 900,width = 800,\n",
    "                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n",
    "                         margin = dict(b = 195))\n",
    "    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n",
    "                                        tickangle = 90))\n",
    "    py.iplot(fig)\n",
    "    \n",
    "    ##if threshold_plot == True : \n",
    "      ##  visualizer = DiscriminationThreshold(algorithm)\n",
    "      ##  visualizer.fit(training_x,training_y)\n",
    "      ##  visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sampling Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "cols    = [i for i in dfm.columns if i not in id_col+target_col]\n",
    "\n",
    "smote_X = dfm[cols]\n",
    "smote_Y = dfm[target_col]\n",
    "\n",
    "#Split train and test data\n",
    "smote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n",
    "                                                                         test_size = .25 ,\n",
    "                                                                         random_state = 111)\n",
    "\n",
    "#oversampling minority class using smote\n",
    "os = SMOTE(random_state = 0)\n",
    "os_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\n",
    "os_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)\n",
    "os_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_prediction(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n",
    "                         cols,\"coefficients\",threshold_plot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
